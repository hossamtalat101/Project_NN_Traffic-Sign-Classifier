import streamlit as st
import tensorflow as tf
import numpy as np
import cv2
import pandas as pd
from PIL import Image

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
st.set_page_config(
    page_title="Traffic Sign AI Explorer",
    page_icon="ğŸš¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# 2. Ø¥Ø¶Ø§ÙØ© Ù„Ù…Ø³Ø§Øª Ø¬Ù…Ø§Ù„ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CSS
st.markdown("""
    <style>
    /* ØªØºÙŠÙŠØ± Ø®Ù„ÙÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ */
    .stApp {
        background-color: #0e1117;
    }
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª (Cards) */
    .metric-card {
        background-color: #161b22;
        padding: 20px;
        border-radius: 15px;
        border: 1px solid #30363d;
        text-align: center;
    }
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†ØµÙˆØµ */
    h1, h2, h3 {
        color: #58a6ff !important;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .result-text {
        font-size: 24px;
        font-weight: bold;
        color: #238636;
    }
    </style>
    """, unsafe_allow_html=True)

# 3. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
@st.cache_resource
def load_assets():
    model = tf.keras.models.load_model('traffic_sign_model.h5')
    labels = pd.read_csv('german-traffic-signs/signnames.csv')
    return model, labels

def process_image(img):
    img_array = np.array(img)
    # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ
    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    equalized = cv2.equalizeHist(gray)
    normalized = equalized / 255.0
    resized = cv2.resize(normalized, (32, 32))
    return resized.reshape(1, 32, 32, 1), equalized

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
model, labels_df = load_assets()

# 4. ØªØµÙ…ÙŠÙ… Ø§Ù„Ù‡ÙŠÙƒÙ„ (Layout)
# --- Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2555/2555013.png", width=100)
    st.title("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    st.info("Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ³ØªØ®Ø¯Ù… Ø´Ø¨ÙƒØ© CNN Ù…Ø¯Ø±Ø¨Ø© Ø¹Ù„Ù‰ 43 ÙØ¦Ø© Ù…Ù† Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±.")
    st.markdown("---")
    source = st.radio("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„:", ["Ø±ÙØ¹ ØµÙˆØ±Ø©", "Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø­ÙŠØ©"])

# --- Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
st.title("ğŸš¦ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø°ÙƒÙŠ Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±")
st.markdown("Ù‚Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨ØªØµÙ†ÙŠÙÙ‡Ø§ ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§ ÙÙˆØ±Ø§Ù‹.")

col1, col2 = st.columns([1, 1], gap="large")

with col1:
    st.subheader("ğŸ“¸ Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„ØµÙˆØ±Ø©")
    if source == "Ø±ÙØ¹ ØµÙˆØ±Ø©":
        input_file = st.file_uploader("", type=["jpg", "png", "jpeg"])
    else:
        input_file = st.camera_input("Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù„Ù„Ø¥Ø´Ø§Ø±Ø©")

    if input_file:
        image = Image.open(input_file)
        st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)

with col2:
    st.subheader("ğŸ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    if input_file:
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù†Ù…Ø§Ø·...'):
            final_img, processed_view = process_image(image)
            prediction = model.predict(final_img)
            class_id = np.argmax(prediction)
            confidence = np.max(prediction) * 100
            sign_name = labels_df.loc[labels_df['ClassId'] == class_id, 'SignName'].values[0]

            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø­Ø§ÙˆÙŠØ© Ù…Ø®ØµØµØ©
            st.markdown(f"""
                <div class="metric-card">
                    <p style="color: #8b949e; margin-bottom: 5px;">Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©</p>
                    <p class="result-text">{sign_name}</p>
                    <hr style="border-color: #30363d;">
                    <p style="color: #8b949e;">Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: <b>{confidence:.2f}%</b></p>
                </div>
            """, unsafe_allow_html=True)
            
            # Ø¹Ø±Ø¶ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ù„ÙˆÙ†
            st.progress(int(confidence))
            
            # Ù‚Ø³Ù… "Ù…Ø§Ø°Ø§ ÙŠØ±Ù‰ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ØŸ"
            with st.expander("ğŸ› ï¸ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© (X-Ray View)"):
                c1, c2 = st.columns(2)
                c1.image(processed_view, caption="Ø¨Ø¹Ø¯ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ†", width=150)
                c2.write("Ù‡Ù†Ø§ Ù†Ù‚ÙˆÙ… Ø¨ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„Ø¸Ø±ÙˆÙ Ø§Ù„Ø¬ÙˆÙŠØ©.")
    else:
        st.warning("ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± ØªØ²ÙˆÙŠØ¯Ù†Ø§ Ø¨ØµÙˆØ±Ø© Ù„Ù„Ø¨Ø¯Ø¡...")

# Ø¥Ø¶Ø§ÙØ© ÙÙˆØªØ± Ø¨Ø³ÙŠØ·
st.markdown("---")
st.caption("Ù…Ø´Ø±ÙˆØ¹ ØªØ®Ø±Ø¬ - ØªØ·ÙˆÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit & TensorFlow")
