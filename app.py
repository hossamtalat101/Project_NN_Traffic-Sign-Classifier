import streamlit as st
import tensorflow as tf
import numpy as np
import cv2
import pandas as pd
from PIL import Image
from gtts import gTTS
import time
import os
import base64

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªÙ†Ø³ÙŠÙ‚ (Modern UI Design) ---
st.set_page_config(page_title="SafeDrive AI System", layout="wide", page_icon="ğŸš¦")

def local_css():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
        * { font-family: 'Cairo', sans-serif; }
        .stApp { background: linear-gradient(135deg, #001524 0%, #002b36 100%); color: white; }
        
        .glass-card {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 25px;
            margin-bottom: 20px;
        }
        
        .main-title { 
            background: linear-gradient(90deg, #d4af37, #f9d71c);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-align: center; font-size: 3.2rem; font-weight: 800; 
        }
        
        .result-box {
            text-align: center;
            border-radius: 15px;
            padding: 20px;
            border-top: 5px solid #d4af37;
            background: rgba(0, 0, 0, 0.3);
        }
        
        .status-pulse {
            width: 12px; height: 12px; background: #3fb950;
            border-radius: 50%; display: inline-block;
            box-shadow: 0 0 0 0 rgba(63, 185, 80, 1);
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(63, 185, 80, 0.7); }
            70% { transform: scale(1); box-shadow: 0 0 0 10px rgba(63, 185, 80, 0); }
            100% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(63, 185, 80, 0); }
        }
        </style>
    """, unsafe_allow_html=True)

local_css()

# --- 2. Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ ---
classes_ar = {
    0:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (20 ÙƒÙ…/Ø³)', 1:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (30 ÙƒÙ…/Ø³)', 2:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (50 ÙƒÙ…/Ø³)',
    3:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (60 ÙƒÙ…/Ø³)', 4:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (70 ÙƒÙ…/Ø³)', 5:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (80 ÙƒÙ…/Ø³)',
    6:'Ù†Ù‡Ø§ÙŠØ© Ù…Ù†Ø·Ù‚Ø© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (80 ÙƒÙ…/Ø³)', 7:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (100 ÙƒÙ…/Ø³)', 8:'ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø±Ø¹Ø© (120 ÙƒÙ…/Ø³)',
    9:'Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„ØªØ¬Ø§ÙˆØ²', 10:'Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„ØªØ¬Ø§ÙˆØ² Ù„Ù„Ø´Ø§Ø­Ù†Ø§Øª', 11:'Ø­Ù‚ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„ØªÙ‚Ø§Ø·Ø¹',
    12:'Ø·Ø±ÙŠÙ‚ Ø°Ùˆ Ø£ÙˆÙ„ÙˆÙŠØ©', 13:'Ø£ÙØ³Ø­ Ø§Ù„Ø·Ø±ÙŠÙ‚ (Yield)', 14:'Ù‚Ù (Stop)', 15:'Ù…Ù…Ù†ÙˆØ¹ Ù…Ø±ÙˆØ± Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª',
    16:'Ù…Ù…Ù†ÙˆØ¹ Ù…Ø±ÙˆØ± Ø§Ù„Ø´Ø§Ø­Ù†Ø§Øª', 17:'Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„Ø¯Ø®ÙˆÙ„', 18:'ØªØ­Ø°ÙŠØ± Ø¹Ø§Ù… (Ø®Ø·Ø±)', 19:'Ù…Ù†Ø­Ù†Ù‰ Ø®Ø·Ø± Ù„Ù„ÙŠØ³Ø§Ø±',
    20:'Ù…Ù†Ø­Ù†Ù‰ Ø®Ø·Ø± Ù„Ù„ÙŠÙ…ÙŠÙ†', 21:'Ù…Ù†Ø­Ù†ÙŠØ§Øª Ù…Ø²Ø¯ÙˆØ¬Ø©', 22:'Ø·Ø±ÙŠÙ‚ ÙˆØ¹Ø± (Ù…Ø·Ø¨Ø§Øª)', 23:'Ø·Ø±ÙŠÙ‚ Ø²Ù„Ù‚',
    24:'Ø·Ø±ÙŠÙ‚ ÙŠØ¶ÙŠÙ‚ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ†', 25:'Ø£Ø¹Ù…Ø§Ù„ Ø·Ø±Ù‚', 26:'Ø¥Ø´Ø§Ø±Ø§Øª Ø¶ÙˆØ¦ÙŠØ©', 27:'Ø¹Ø¨ÙˆØ± Ù…Ø´Ø§Ø©',
    28:'Ø¹Ø¨ÙˆØ± Ø£Ø·ÙØ§Ù„', 29:'Ø¹Ø¨ÙˆØ± Ø¯Ø±Ø§Ø¬Ø§Øª Ù‡ÙˆØ§Ø¦ÙŠØ©', 30:'Ø§Ø­Ø°Ø± Ù…Ù† Ø§Ù„Ø¬Ù„ÙŠØ¯/Ø§Ù„Ø«Ù„Ø¬',
    31:'Ø¹Ø¨ÙˆØ± Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø¨Ø±ÙŠØ©', 32:'Ù†Ù‡Ø§ÙŠØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙˆØ¯', 33:'Ø¥Ù„Ø²Ø§Ù… Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù„Ù„ÙŠÙ…ÙŠÙ†',
    34:'Ø¥Ù„Ø²Ø§Ù… Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù„Ù„ÙŠØ³Ø§Ø±', 35:'Ø¥Ù„Ø²Ø§Ù… Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù„Ù„Ø£Ù…Ø§Ù… ÙÙ‚Ø·', 36:'Ø¥Ù„Ø²Ø§Ù… Ù„Ù„Ø£Ù…Ø§Ù… Ø£Ùˆ Ø§Ù„ÙŠÙ…ÙŠÙ†',
    37:'Ø¥Ù„Ø²Ø§Ù… Ù„Ù„Ø£Ù…Ø§Ù… Ø£Ùˆ Ø§Ù„ÙŠØ³Ø§Ø±', 38:'Ø§Ø¨Ù‚ Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ†', 39:'Ø§Ø¨Ù‚ Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±',
    40:'Ø¯ÙˆØ§Ø± Ø¥Ù„Ø²Ø§Ù…ÙŠ', 41:'Ù†Ù‡Ø§ÙŠØ© Ù…Ù†Ø¹ Ø§Ù„ØªØ¬Ø§ÙˆØ²', 42:'Ù†Ù‡Ø§ÙŠØ© Ù…Ù†Ø¹ Ø§Ù„ØªØ¬Ø§ÙˆØ² Ù„Ù„Ø´Ø§Ø­Ù†Ø§Øª'
}

# --- 3. Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ‚Ù†ÙŠØ© (Processing & AI) ---
@st.cache_resource
def load_assets():
    # ØªØ£ÙƒØ¯ Ø£Ù† Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯
    return tf.keras.models.load_model('traffic_sign_model.h5')

model = load_assets()

def get_gradcam_heatmap(img_array, model):
    try:
        last_conv_layer_name = [layer.name for layer in model.layers if "conv2d" in layer.name][-1]
        grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = grad_model(img_array)
            pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        heatmap = last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)
        return heatmap.numpy()
    except:
        return np.zeros((32, 32))

# --- 4. Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© ---
st.markdown('<h1 class="main-title">SAFE DRIVE AI SYSTEM</h1>', unsafe_allow_html=True)

if 'history' not in st.session_state:
    st.session_state.history = []

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
with st.sidebar:
    st.markdown("### <div class='status-pulse'></div> System: Active", unsafe_allow_html=True)
    st.markdown("---")
    st.markdown("### ğŸ•’ Recent Logs")
    for entry in reversed(st.session_state.history[-5:]):
        st.caption(f"âœ… {entry['time']} - {entry['label']}")

tab1, tab2, tab3 = st.tabs(["ğŸš€ Real-time Discovery", "ğŸ”¬ AI Insights", "ğŸ‘¥ Developers"])

with tab1:
    col1, col2 = st.columns([1, 1], gap="large")
    
    with col1:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        source = st.radio("Input Method:", ["Upload Image", "Live Camera"], horizontal=True)
        if source == "Upload Image":
            uploaded_file = st.file_uploader("Select image...", type=["jpg", "jpeg", "png"])
        else:
            uploaded_file = st.camera_input("Snapshot")
        st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        if uploaded_file:
            start_time = time.time()
            img = Image.open(uploaded_file).convert('RGB')
            img_np = np.array(img)
            
            # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©
            gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
            equ = cv2.equalizeHist(gray)
            processed = cv2.resize(equ, (32, 32)).reshape(1, 32, 32, 1) / 255.0
            
            # Ø§Ù„ØªÙˆÙ‚Ø¹
            preds = model.predict(processed)
            idx = np.argmax(preds)
            confidence = np.max(preds) * 100
            result_ar = classes_ar.get(idx, "Unknown")
            
            # Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            st.session_state.history.append({"time": time.strftime("%H:%M"), "label": result_ar})
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            st.markdown(f"""
                <div class="result-box">
                    <h2 style="color:#d4af37;">{result_ar}</h2>
                    <p>Accuracy Score: {confidence:.1f}%</p>
                    <p style="font-size:0.8rem; color:#839496;">Processed in: {(time.time()-start_time)*1000:.0f}ms</p>
                </div>
            """, unsafe_allow_html=True)
            
            # ØªÙ†Ø¨ÙŠÙ‡ ØµÙˆØªÙŠ
            tts = gTTS(text=f"Ø§Ù†ØªØ¨Ù‡ØŒ {result_ar}", lang='ar')
            tts.save('alert.mp3')
            st.audio('alert.mp3', format="audio/mp3", autoplay=True)
        else:
            st.info("System is ready. Please provide an input image.")

with tab2:
    if uploaded_file:
        heatmap = get_gradcam_heatmap(processed, model)
        heatmap_resized = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))
        heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)
        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
        overlayed_img = cv2.addWeighted(img_np, 0.6, heatmap_colored, 0.4, 0)
        
        c1, c2 = st.columns(2)
        c1.image(img, caption="Original Input", use_container_width=True)
        c2.image(overlayed_img, caption="Grad-CAM: Heatmap (Focus Area)", use_container_width=True)
        
        st.markdown("#### Top 3 Probabilities:")
        top_3 = np.argsort(preds[0])[-3:][::-1]
        for i in top_3:
            st.write(f"**{classes_ar[i]}**: {preds[0][i]*100:.1f}%")
            st.progress(float(preds[0][i]))

with tab3:
    st.markdown("<div style='display: flex; justify-content: space-around;'>", unsafe_allow_html=True)
    for name in ["Hossam Talat", "Fatteh", "Osama"]:
        st.markdown(f"<div class='glass-card' style='text-align:center;'><h4>{name}</h4><p>Engineer</p></div>", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)
